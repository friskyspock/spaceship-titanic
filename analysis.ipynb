{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data = pd.read_csv('train.csv')\n",
    "raw_test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primitive analysis function, I use to look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_analysis(dataset):\n",
    "    df = pd.DataFrame(columns=['Datatype', 'NA values %', 'Unique values', 'mode', 'mode contribution %', 'min value','max value'])\n",
    "    length = len(dataset.index)\n",
    "    for col in dataset.columns:\n",
    "        row_df = pd.DataFrame({\n",
    "                                'Datatype':dataset[col].dtype,\n",
    "                                'NA values %':round(dataset[col].isna().sum()*100/length,2),\n",
    "                                'Unique values':dataset[col].nunique(),\n",
    "                                'mode':dataset[col].value_counts().index[0],\n",
    "                                'mode contribution %':round(dataset[col].value_counts()[0]*100/length,2),\n",
    "                                'min value':'none' if dataset[col].dtype=='object' else dataset[col].min(),\n",
    "                                'max value':'none' if dataset[col].dtype=='object' else dataset[col].max()\n",
    "                                },\n",
    "                                index=[col])\n",
    "        df = pd.concat([df,row_df])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analysis(raw_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_analysis(raw_test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in above analysis, **Cabin** column has so many unique values and replacing the NA values from it can be statistically impossible. Thus we chose to exclude the rows from dataset which have NA values in **Cabin** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = raw_train_data[raw_train_data['Cabin'].notna()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting important information from some columns\n",
    "\n",
    "- **PassengerId** column:\\\n",
    "    As per data description, *'This is an unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.'*\\\n",
    "    We will make two new columns as **Group** and **PeopleId** \n",
    "    \n",
    "    \n",
    "- **Cabin** column:\\\n",
    "    As per data description, *'The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.'*\\\n",
    "    We will split this column into **Deck**, **Num** and **Side**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_columns(raw_dataset):\n",
    "    dataset = raw_dataset.copy()\n",
    "\n",
    "    dataset['Group'] = dataset['PassengerId'].str[:4].astype(float)\n",
    "    dataset['PeopleId'] = dataset['PassengerId'].str[-2:].astype(float)\n",
    "    \n",
    "    dataset['Deck'] = dataset['Cabin'].str[0]\n",
    "    dataset['Num'] = dataset['Cabin'].str[2:-2].astype(float)\n",
    "    dataset['Side'] = dataset['Cabin'].str[-1]\n",
    "\n",
    "    dataset = dataset.drop(['PassengerId','Cabin'], axis=1)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_data = split_columns(train_data)\n",
    "test_data = split_columns(raw_test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing unneccessary columns\n",
    "Since column **Name** won't really help in training algorithm, we will remove it from our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_columns = ['Name']\n",
    "\n",
    "train_data = train_data.drop(remove_columns, axis=1)\n",
    "test_data = test_data.drop(remove_columns, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filling Missing Values\n",
    "\n",
    "From our analysis above we can fill out columns with mode which have less amount of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_columns = ['HomePlanet','CryoSleep','Destination','Age','VIP','RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']\n",
    "\n",
    "def fillmode(dataset,catcol):\n",
    "    for col in catcol:\n",
    "        dataset[col].fillna(dataset[col].mode()[0], inplace=True)\n",
    "\n",
    "fillmode(train_data,mode_columns)\n",
    "fillmode(test_data,mode_columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns have boolean inputs, we can quickly change into 1's and 0's as following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_columns = ['CryoSleep','VIP']\n",
    "\n",
    "def boolean_to_num(dataset,columns):\n",
    "    for col in columns:\n",
    "        dataset[col] = dataset[col].astype(int)\n",
    "\n",
    "boolean_to_num(train_data,boolean_columns)\n",
    "boolean_to_num(test_data,boolean_columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform 'One hot encoding' on categorical columns, basically it will create dummy columns for each category in column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['HomePlanet','Destination','Deck','Side']\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "df1 = pd.DataFrame(ohe.fit_transform(train_data[categorical_columns]))\n",
    "df1.index = train_data.index\n",
    "train_data = train_data.drop(categorical_columns, axis=1)\n",
    "train_data = pd.concat([train_data,df1], axis=1)\n",
    "\n",
    "df2 = pd.DataFrame(ohe.transform(test_data[categorical_columns]))\n",
    "df2.index = test_data.index\n",
    "test_data = test_data.drop(categorical_columns, axis=1)\n",
    "test_data = pd.concat([test_data,df2], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is cleaned and ready to use in any model of our wish"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save this cleaned data in separate csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('cleaned_train.csv', index=False)\n",
    "test_data.to_csv('cleaned_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71ce2b37d068746d6319cfebb01c1cb1b7b9360c2e66c0d2761ec509a11075b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
